level = 0.95)
# png(filename = "../figs/papertukey.png",
#     width = 600, height = 600,
#     bg = "transparent")
plot(paper_tukey_CI,
xlab       = "Tensile Strength (kPa)",
sub        = "- Hardwood data -",
cex.axis   = 1.2,
cex        = 2)
# dev.off()
# Situation 2: all vs. B
paper$Hardwood  <- relevel(paper$Hardwood,
ref = "B")
model2          <- aov(TS_kPA~Hardwood,
data = paper)
paper_dunnett   <- glht(model2,
linfct = mcp(Hardwood = "Dunnett"))
paper_dunnett_CI <- confint(paper_dunnett,
level = 0.95)
# png(filename = "../figs/paperdunnett.png",
#     width = 600, height = 600,
#     bg = "transparent")
plot(paper_dunnett_CI,
xlab       = "Tensile Strength (kPa)",
sub        = "- Hardwood data -",
cex.axis   = 1.2,
cex        = 2)
# dev.off()
#==========
## Sample size calculations for anova
a       <- 4
alpha   <- 0.05
sigma   <- 7
delta   <- 12
beta    <- 0.2
# Case 1: two levels symmetrically biased about the grand mean
tau <- c(-delta/2,
delta/2,
rep(0, a-2)) # define tau vector
n   <- 2        # initial n
while (qf(1 - alpha, a - 1, a*(n - 1)) >
qf(beta, a - 1, a*(n - 1), n*sum(tau^2)/sigma^2)) n <- n + 1
# Using power.anova.test():
vartau <- var(tau)
power.anova.test(groups = 4,
between.var = vartau,
within.var = sigma^2,
sig.level = alpha,
power = 1-beta)$n
# Case 2: one levels biased relative to the others
tau <- c(-delta*(a - 1)/a,
rep(delta/a, a-1)) # define tau vector
vartau <- var(tau)
power.anova.test(groups = 4,
between.var = vartau,
within.var = sigma^2,
sig.level = alpha,
power = 1-beta)$n
installed.packages("irace")
install.packages("irace")
install.packages("irace")
installed.packages("irace")
defaults write org.R-project.R force.LANG en_US.UTF-8
install.packages("irace")
install.packages("irace")
system("defaults write org.R-project.R force.LANG en_US.UTF-8")
packages_needed <- c("p.adjust")
for (package_name in packages_needed) {
if (!(package_name %in% rownames(installed.packages()))){
install.packages(package_name)
}
}
#call the necessary package
library(p.adjust)
library(MASS)
fix(Boston)
names(Boston)
summary(Boston)
?Boston
lm.fit = lm(medv~lstat)
attach(Boston)
lm.fit = lm(medv~lstat)
lm.fit
summary(lm.fit)
names(lm.fit)
coef(lm.fit)
confint(lm.fit)
predict(lm.fit, data.frame(lstat=c(5,10,15)), interval = "confidence")
predict(lm.fit, data.frame(lstat=c(5,10,15)), interval = "prediction")
plot(lstat,medv)
plot(lstat,medv)
abline(lm.fit)
plot(lstat,medv)
abline(lm.fit)
abline(lm.fit,lwd = 3)
abline(lm.fit, lwd = 3, col = "red")
plot(lstat, medv, col = "red")
plot(lstat,medv, pch = 20)
plot(lstat,medv,pch="+")
plot(1:20,1:20,pch=1:20)
par(mfrow=c(2,2))
plot(lm.fit)
plot(predict(lm.fit), residuals(lm.fit))
the residuals
plot(predict(lm.fit), rstudent(lm.fit))
plot(hatvalues(lm.fit))
which.max(hatvalues(lm.fit))
lm.fit = lm(medv~lstat+age,data = Boston)
summary(lm.fit)
riables
lm.fit = lm(medv~,data=Boston)
lm.fit = lm(medv~.,data=Boston)
summary(lm.fit)
summary(lm.fit)$r.sq
summary(lm.fit)$sigma
library(car)
install.packages("car")
library(car)
vif(lm.fit)
lm.fit1 = lm(medv~.-age, data =Boston)
summary(lm.fit1)
lm.fit1 = update(lm.fit,~.-age)
summary(lm(medv∼lstat*age,data=Boston))
summary(lm(medv∼lstat*age,data=Boston))
summary(lm(medv∼lstat * age,data=Boston)
summary(lm(medv~lstat*age,data = Boston))
lstat^2 using the I function call
lm.fit2 = lm(medv~lstat+I(lstat^2))
summary(lm.fit2)
lm.fit = lm(medv~lstat)
anova(lm.fit,lm.fit2)
par = (mfrow = c(2,2))
par (mfrow = c(2,2))
plot(lm.fit2)
ion with higher order polynomials using the poly() function
lm.fit5 = lm(medv~poly(lstat,5))
summary(lm.fit5)
summary(lm(medv∼log(rm),data=Boston))
summary(lm(medv~log(rm),data=Boston))
EDICTORS
names(Carseats)
names(Carseats)
library(ISLR)
summary(Carseats)
install.packages("ISLR")
library(ISLR)
summary(Carseats)
names(Carseats)
attach(Carseats)
lm.fit = lm(Sales~.+Income:Advertising+Price:Age,data=Carseats)
summary(lm.fit)
#get the dummy vars
constrasts(ShelveLoc)
constrasts(shelveLoc)
contrasts(ShelveLoc)
library(ISLR)
names(Smarket)
dim(Smarket)
summary(Smarket)
pairs(Smarket)
cor(Smarket)
cor(Smarket[,-9])
plot(Volume)
attach(Smarket)
plot(Volume)
plot(Volume, color = 'red')
plot(Volume, col = "red")
plot(Volume, col = 2)
#do a logistic regression with lag and volume to predict direction
glm.fits = glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data = Smarket, family = binomial)
summary(glm.fits)
coef(glm.fits)
glm.probs = predict(glm.fits, type = "response")
glm.probs[1:10]
contrasts(Direction)
glm.pred = rep("Down",1250)
glm.pred[glm.probs > 0.5] = "Up"
table(glm.pred, Direction)
(507+145)/1250
mean(glm.pred == Direction)
train = (Year<2005)
Smarket.2005 = Smarket[!train,]
glm.fits = glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data = Smarket.2005, family = binomial)
summary(glm.fits)
dim(glm.fits)
dim(Smarket.2005)
dim(Smarket.2005)[0]
dim(Smarket.2005)[[0]]
dim(Smarket.2005)
rows(Smarket.2005)
row(Smarket.2005)
nrow(Smarket.2005)
glm.pred = rep("Down",nrow(Smarket.2005))
glm.pred[glm.probs >.5]="Up"
table(glm.pred, Direction.2005)
Direction.2005=Direction[!train]
table(glm.pred, Direction.2005)
glm.pred = rep("Down",nrow(Smarket.2005))
glm.pred[glm.probs >.5]="Up"
glm.probs = predict(glm.fits, Smarket.2005, type = "response")
glm.pred = rep("Down",nrow(Smarket.2005))
glm.pred[glm.probs >.5]="Up"
table(glm.pred, Direction.2005)
mean(glm.pred == Direction.2005)
mean(glm.pred != Direction.2005)
glm.fits=glm(Direction∼Lag1+Lag2,data=Smarket ,family=binomial, subset=train)
glm.fits=glm(Direction~Lag1+Lag2,data=Smarket ,family=binomial, subset=train)
glm.probs=predict(glm.fits,Smarket.2005,type="response")
glm.pred=rep("Down",252)
glm.pred[glm.probs >.5]="Up"
table(glm.pred,Direction .2005)
table(glm.pred,Direction.2005)
mean(glm.pred==Direction .2005)
mean(glm.pred==Direction.2005)
predict(glm.fits,newdata=data.frame(Lag1=c(1.2,1.5), Lag2=c(1.1,-0.8)),type="response")
library(MASS)
lda.fit = lda(Direction~Lag1+Lag2, data = Smarket, subset = train)
lda.fit
plot(lda.fit)
lda.pred = predict(lda.fit,Smarket.2005)
names(lda.pred)
lda.class = lda.pred$class
table(lda.class, Direction.2005)
mean(lda.class == Direction.2005)
sum(lda.pred$posterior[,1]>=.5)
sum(lda.pred$posterior[,1]<.5)
lda.pred$posterior[1:20,1]
lda.class[1:20]
sum(lda.pred$posterior[,1]>=.9)
qda.fit = qda(Direction~Lag1+Lag2, data=Smarket, subset = train)
qda.fit
qda.class = predict(qda.fit, Smarket.2005)$class
table(qda.class, Direction.2005)
qda.class
mean(qda.class == Direction.2005)
library(class)
train.X = cbind(Lag1, Lag2)[train,]
View(train.X)
test.X = cbind(Lag1, Lag2)[!train,]
train.Direction = Direction[train]
set.seed(1)
knn.pred = knn(train.X, test.X, train.Direction, k =1)
table(knn.pred, Direction.2005)
knn.pred = knn(train.X, test.X, train.Direction, k = 3)
table(knn.pred, Direction.2005)
mean(knn.pred == Direction.2005)
ion to the caravan insurance data
dim(Caravan)
attach(Caravan)
summary(Purchase)
standardized.X = scale(Caravan[-86,])
standardized.X = scale(Caravan[,-86])
var(Caravan[,1])
var(Caravan[,2])
var(standardized.X[,1])
test = 1:1000
train.X = standardized.X[-test,]
test.X = standardized.X[test,]
train.Y = Purchase[-test]
test.Y = Purchase[test]
knn.pred = knn(train.X, test.X, train.Y, k=1)
mean(test.Y!= knn.pred)
mean(test.Y!="No")
table(knn.pred,test.Y)
#BEFORE STARTING OUR CLASS, PLEASE RUN THIS SNIPPET TO INSTALL/LOAD OUR LIBRARIES NEEDED FOR THIS LESSON
packages_needed <- c('car', 'nortest')
for (package_name in packages_needed) {
if (!(package_name %in% rownames(installed.packages()))){
install.packages(package_name)
}
}
for (i in 1:length(packages_needed))
{
library(packages_needed[[i]],character.only=TRUE)
}
#SLEEP EXPERIMENT
#variables
conf_alpha<- 0.95
power_beta<- 0.85
pilot_n <- 6
#BEFORE STARTING OUR CLASS, PLEASE RUN THIS SNIPPET TO INSTALL/LOAD OUR LIBRARIES NEEDED FOR THIS LESSON
packages_needed <- c('car', 'nortest')
for (package_name in packages_needed) {
if (!(package_name %in% rownames(installed.packages()))){
install.packages(package_name)
}
}
for (i in 1:length(packages_needed))
{
library(packages_needed[[i]],character.only=TRUE)
}
#SLEEP EXPERIMENT
#variables
conf_alpha<- 0.95
power_beta<- 0.85
pilot_n <- 6
x<- rnorm(6,mean=7,sd=1)
y<- rnorm(6,mean=7,sd= 3)
z<- rnorm(6,mean=7,sd=2.5)
y
z
x
x<- rnorm(6,mean=8,sd=1)
x
x<- rnorm(6,mean=7.6,sd=1)
y<- rnorm(6,mean=7.3,sd= 1.65)
z<- rnorm(6,mean=7.4,sd=1.45)
z
y
x
df <- as.data.frame(c(x,y,z))
View(df)
View(df)
View(df)
View(df)
View(df)
df <- as.data.frame(x,y,z)
l<- as.list(x,y,z)
View(l)
l<- as.list(c(x,y,z))
df <- data.frame(x,y,z)
View(df)
colnames(df) <- c('Control', 'Test', 'Placebo')
View(df)
setwd("~/Dropbox/Doutorado/R-repo/Datasets")
write.csv(df, file="sleep_exp_pilot.csv")
write.csv(df, file="sleep_exp_pilot.csv",row.names=F)
sleep_pilot <- read.csv('sleep_exp_pilot.csv', header = TRUE)
View(sleep_pilot)
power.t.test(n = 6, delta = 1, sd = sd(sleep_pilot$Control), sig.level = 0.05, type = "one.sample")
power.t.test(n = 6, delta = 1, sd = sd(sleep_pilot$Test), sig.level = 0.05, type = "one.sample")
power.t.test(n = 6, delta = 1, sd = sd(sleep_pilot$Placebo), sig.level = 0.05, type = "one.sample")
power.t.test(n = 6, delta = 1, sd = sd(sleep_pilot$Test), sig.level = 0.05, type = "one.sample")
power.t.test(power = 0.85, delta = 1, sd = sd(sleep_pilot$Placebo), sig.level = 0.05, type = "one.sample")
x<- rnorm(23,mean=7.6,sd=1)
y<- rnorm(23,mean=7.3,sd= 1.65)
z<- rnorm(23,mean=7.4,sd=1.45)
l<- as.list(c(x,y,z))
df <- data.frame(x,y,z)
colnames(df) <- c('Control', 'Test', 'Placebo')
write.csv(df, file="sleep_exp_main.csv",row.names=F)
sleep_main <- read.csv('sleep_exp_main.csv')
par(mfrow=c(1,3))
qqPlot(sleep_main$Control, cex=1.5,pch=16, las=1)
qqPlot(sleep_main$Test, cex=1.5,pch=16, las=1)
qqPlot(sleep_main$Placebo, cex=1.5,pch=16, las=1)
res_shapiro <- list("control" = NULL, "Test" = NULL, "Placebo" = NULL)
for(c in colnames(sleep_main)){
res_shapiro[[c]] <- shapiro.test(df[[c]])
}
#shapiro-wilk test
#list of results
res_shapiro <- list("Control" = NULL, "Test" = NULL, "Placebo" = NULL)
for(c in colnames(sleep_main)){
res_shapiro[[c]] <- shapiro.test(df[[c]])
}
res_shapiro[['Control']]
res_shapiro[['Placebo']]
res_shapiro[['Test']]
x<- rnorm(23,mean=7.6,sd=1)
y<- rnorm(23,mean=7.3,sd= 1.65)
z<- rnorm(23,mean=7.4,sd=1.45)
x<- rnorm(23,mean=7.6,sd=1)
y<- rnorm(23,mean=7.3,sd= 1.65)
z<- rnorm(23,mean=7.4,sd=1.45)
df<- data.frame(x,y,z)
colnames(df)<- c("Control", "Test", "Placebo")
write.csv(df, row.names = F)
x<- rnorm(23,mean=7.6,sd=1)
y<- rnorm(23,mean=7.3,sd= 1.11)
z<- rnorm(23,mean=7.4,sd=1.2)
df<- data.frame(x,y,z)
colnames(df)<- c("Control", "Test", "Placebo")
write.csv(df, row.names = F)
x<- rnorm(23,mean=7.6,sd=1)
y<- rnorm(23,mean=7.3,sd= 1.11)
z<- rnorm(23,mean=7.4,sd=1.2)
df<- data.frame(x,y,z)
colnames(df)<- c("Control", "Test", "Placebo")
write.csv(df, file = 'sleep_exp_pilot.csv', row.names = F)
x<- rnorm(6,mean=7.6,sd=1)
y<- rnorm(6,mean=7.3,sd= 1.11)
z<- rnorm(6,mean=7.4,sd=1.2)
df<- data.frame(x,y,z)
colnames(df)<- c("Control", "Test", "Placebo")
write.csv(df, file = 'sleep_exp_pilot.csv', row.names = F)
x<- rnorm(23,mean=7.6,sd=1)
y<- rnorm(23,mean=7.3,sd= 1.11)
z<- rnorm(23,mean=7.4,sd=1.2)
df<- data.frame(x,y,z)
colnames(df)<- c("Control", "Test", "Placebo")
write.csv(df, file = 'sleep_exp_main.csv', row.names = F)
sleep_main <- read.csv('sleep_exp_main.csv')
par(mfrow=c(1,3))
qqPlot(sleep_main$Control, cex=1.5,pch=16, las=1)
qqPlot(sleep_main$Test, cex=1.5,pch=16, las=1)
qqPlot(sleep_main$Placebo, cex=1.5,pch=16, las=1)
#shapiro-wilk test
#list of results
res_shapiro <- list("Control" = NULL, "Test" = NULL, "Placebo" = NULL)
for(c in colnames(sleep_main)){
res_shapiro[[c]] <- shapiro.test(df[[c]])
}
res_shapiro[['Control']]
res_shapiro[['Test']]
res_shapiro[['Placebo']]
#shapiro-wilk test
#list of results
res_shapiro <- list("Control" = NULL, "Test" = NULL, "Placebo" = NULL)
for(c in colnames(sleep_main)){
res_shapiro[[c]] <- shapiro.test(df[[c]])
}
res_shapiro[['Control']]
res_shapiro[['Test']]
res_shapiro[['Placebo']]
x<- rnorm(23,mean=7.6,sd=1)
y<- rnorm(23,mean=7.3,sd= 1.11)
z<- rnorm(23,mean=7.4,sd=1.2)
df<- data.frame(x,y,z)
colnames(df)<- c("Control", "Test", "Placebo")
write.csv(df, file = 'sleep_exp_main.csv', row.names = F)
res_shapiro <- list("Control" = NULL, "Test" = NULL, "Placebo" = NULL)
for(c in colnames(sleep_main)){
res_shapiro[[c]] <- shapiro.test(df[[c]])
}
res_shapiro[['Control']]
res_shapiro[['Test']]
res_shapiro[['Placebo']]
power.t.test(n = 6, delta = 1, sd = sd(sleep_pilot$Control), sig.level = 0.05, type = "one.sample")
power.t.test(n = 6, delta = 1, sd = sd(sleep_pilot$Test), sig.level = 0.05, type = "one.sample")
power.t.test(n = 6, delta = 1, sd = sd(sleep_pilot$Placebo), sig.level = 0.05, type = "one.sample")
#Placebo was the lowest, let's determine the sample size taking placebo into consideration
#power t-test to determine sample size
power.t.test(power = 0.85, delta = 1, sd = sd(sleep_pilot$Placebo), sig.level = 0.05, type = "one.sample")
fligner.test(sleep_main)
#plot our residuals
resids <- apply(sleep_main, 1, function (x) (x- mean(x)))
resids <- list("Test" = resids[1,], "Control" = resids[2,], "Placebo" = resids[3,] )
stripchart(x = resids,
vertical =  TRUE,
pch = 16,
cex = 1.5,
las= 1,
xlab = 'mean',
ylab = 'residuals')
stripchart(x = resids,
vertical =  TRUE,
pch = 16,
cex = 1.5,
las= 1,
xlab = 'mean',
ylab = 'residuals')
#durbin watson for two samples
durbinWatsonTest(lm(sleep_main$Control + sleep_main$Test + sleep_main$Placebo ~1))
d covariance
cor(sleep_main)
cor(sleep_main)
cov(sleep_main)
sleep_pilot <- read.csv('sleep_exp_pilot.csv', header = TRUE)
apply(sleep_pilot,round)
apply(sleep_pilot,1,round)
apply(sleep_pilot,0,round)
apply(sleep_pilot,3,round)
apply(sleep_pilot,2,round)
apply(sleep_main,2,round)
apply(sleep_main,2,round(digits = 2))
apply(sleep_main,2,function (x) round(x, digits = 2))
sleep_pilot <-as.data.frame(apply(sleep_main,2,function (x) round(x, digits = 2)))
sleep_main <-as.data.frame(apply(sleep_main,2,function (x) round(x, digits = 2)))
sleep_pilot <- read.csv('sleep_exp_pilot.csv', header = TRUE)
sleep_pilot <-as.data.frame(apply(sleep_pilot,2,function (x) round(x, digits = 2)))
write.csv(sleep_main, file = 'sleep_exp_main.csv', row.names = F)
write.csv(sleep_pilot, file = 'sleep_exp_pilot.csv', row.names = F)
#variables
conf_alpha<- 0.95
power_beta<- 0.85
pilot_n <- 6
sleep_pilot <- read.csv('sleep_exp_pilot.csv', header = TRUE)
#power t-test to check for power
power.t.test(n = 6, delta = 1, sd = sd(sleep_pilot$Control), sig.level = 0.05, type = "one.sample")
power.t.test(n = 6, delta = 1, sd = sd(sleep_pilot$Test), sig.level = 0.05, type = "one.sample")
power.t.test(n = 6, delta = 1, sd = sd(sleep_pilot$Placebo), sig.level = 0.05, type = "one.sample")
power.t.test(power = 0.85, delta = 1, sd = sd(sleep_pilot$Placebo), sig.level = 0.05, type = "one.sample")
power.t.test(n = 6, delta = 1, sd = sd(sleep_pilot$Placebo), sig.level = 0.05, type = "one.sample")
power.t.test(n = 6, delta = 1, sd = sd(sleep_pilot$Test), sig.level = 0.05, type = "one.sample")
power.t.test(n = 6, delta = 1, sd = sd(sleep_pilot$Control), sig.level = 0.05, type = "one.sample")
power.t.test(power = 0.85, delta = 1, sd = sd(sleep_pilot$Test), sig.level = 0.05, type = "one.sample")
#power t-test to determine sample size
power.t.test(power = 0.85, delta = 1, sd = sd(sleep_pilot$Placebo), sig.level = 0.05, type = "one.sample")
power.t.test(power = 0.85, delta = 1, sd = sd(sleep_pilot$Control), sig.level = 0.05, type = "one.sample")
View(sleep_main)
x<- rnorm(24,mean=7.6,sd=1)
y<- rnorm(24,mean=7.3,sd= 1.11)
z<- rnorm(24,mean=7.4,sd=1.2)
df<- data.frame(x,y,z)
colnames(df)<- c("Control", "Test", "Placebo")
df <-as.data.frame(apply(df,2,function (x) round(x, digits = 2)))
x<- rnorm(24,mean=7.6,sd=1)
y<- rnorm(24,mean=7.3,sd= 1.11)
z<- rnorm(24,mean=7.4,sd=1.2)
df<- data.frame(x,y,z)
colnames(df)<- c("Control", "Test", "Placebo")
df <-as.data.frame(apply(df,2,function (x) round(x, digits = 2)))
write.csv(df, file = 'sleep_exp_main.csv', row.names = F)
sleep_main <- read.csv('sleep_exp_main.csv')
res_shapiro <- list("Control" = NULL, "Test" = NULL, "Placebo" = NULL)
for(c in colnames(sleep_main)){
res_shapiro[[c]] <- shapiro.test(df[[c]])
}
res_shapiro[['Control']]
res_shapiro[['Test']]
res_shapiro[['Placebo']]
